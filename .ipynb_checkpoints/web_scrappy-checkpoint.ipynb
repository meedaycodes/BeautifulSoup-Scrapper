{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#this is a webscrappring program scripted to obtain real estate information from UK's most popular property listing website\n",
    "#it is important to use a cached version of a website for scrapping due to the dynamic nature of most websites\n",
    "\n",
    "#import the necessary libraries\n",
    "import requests \n",
    "from  bs4 import BeautifulSoup\n",
    "import pandas\n",
    "\n",
    "#save the url in a avariable called url \n",
    "url = \"https://www.zoopla.co.uk/for-sale/property/london/?search_source=refine&pn=2\"\n",
    "\n",
    "#An empty list is created to store the obtained dictionary\n",
    "prop_csv = []\n",
    "\n",
    "#this line loops through the pages of the website\n",
    "pages = range(2, 10,1)\n",
    "for page  in pages:\n",
    "    \n",
    "    #N:B it is important that you study the structure of each website to understand the path to each page\n",
    "    #first convert the url to a list\n",
    "    url = list(url)\n",
    "    \n",
    "    #in this case we check and handle situations where the page extends to double digit number i.e > 10\n",
    "    if url[-3] == \"=\":\n",
    "        url[-2:]= str(page)\n",
    "    else:\n",
    "        url[-1] = str(page)\n",
    "    url = \"\".join(url)\n",
    "    #the request method gets the content of the parsed webpage\n",
    "    req = requests.get(url)\n",
    "    cont = req.content\n",
    "    \n",
    "    #the soup variable is used to store the request content in an html format\n",
    "    soup = BeautifulSoup(cont,\"html.parser\")\n",
    "    \n",
    "    #the prop variable stores the section of the page that contains information we are scrapping for\n",
    "    prop=soup.find_all(\"div\", {\"data-testid\":\"regular-listings\"})\n",
    "    \n",
    "    # we loop through each page and grab the following properties\n",
    "    for item in prop:\n",
    "        # the d dictonary is used to store the values of each property onatained at the end of each loop\n",
    "        d = {}\n",
    "        try:\n",
    "            d[\"prop_price\"]= item.find(\"div\",{\"data-testid\":\"listing-price\"}).text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            d[\"prop_desc\"] = item.find(\"h2\", {\"data-testid\":\"listing-title\"}).text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            d[\"date_published\"] = item.find(\"span\",{\"data-testid\":\"date-published\"}).text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            d[\"prop_address\"] = item.find(\"p\",{\"data-testid\":\"listing-description\"}).text\n",
    "        except:\n",
    "            pass\n",
    "        # we then add each dictionary to the list prop_csv declared from the beginning\n",
    "        prop_csv.append(d)\n",
    "\n",
    "        \n",
    "# we create a pandas frame and convert the list to a csv file          \n",
    "df = pandas.DataFrame(prop_csv)\n",
    "df.to_csv(\"london_prop_data5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
